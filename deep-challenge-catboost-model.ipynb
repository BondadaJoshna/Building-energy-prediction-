{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import os, gc, sys, warnings, random, math, psutil, pickle\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using CatBoost Method for create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "######### Helpers ##########\n",
    "\n",
    "## Seeder\n",
    "# :seed to make all processes deterministic     # type: int\n",
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "## Simple \"Memory profilers\" to see memory usage\n",
    "def get_memory_usage():\n",
    "    return np.round(psutil.Process(os.getpid()).memory_info()[0]/2.**30, 2) \n",
    "        \n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f%s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "\n",
    "\n",
    "## Memory Reducer\n",
    "# :df pandas dataframe to reduce size             # type: pd.DataFrame()\n",
    "# :verbose                                        # type: bool\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        if col!=TARGET:\n",
    "            col_type = df[col].dtypes\n",
    "            if col_type in numerics:\n",
    "                c_min = df[col].min()\n",
    "                c_max = df[col].max()\n",
    "                if str(col_type)[:3] == 'int':\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype(np.int16)\n",
    "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                        df[col] = df[col].astype(np.int64)  \n",
    "                else:\n",
    "                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                        df[col] = df[col].astype(np.float16)\n",
    "                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                        df[col] = df[col].astype(np.float32)\n",
    "                    else:\n",
    "                        df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Vars ##############\n",
    "\n",
    "SEED = 42\n",
    "LOCAl_TEST = False\n",
    "seed_everything(SEED)\n",
    "TARGET = 'meter_reading'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "test_df = pd.read_csv('test.csv') # Load test data\n",
    "\n",
    "building_df = pd.read_csv('building_metadata.csv')\n",
    "\n",
    "train_weather_df = pd.read_csv('weather_train.csv')\n",
    "\n",
    "test_weather_df = pd.read_csv('weather_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['building_id', 'meter', 'timestamp', 'meter_reading'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'DT_D'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2656\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2657\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'DT_D'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-36fea689d4f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuilding_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbuilding_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'site_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'drop'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'DT_D'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m<=\u001b[0m\u001b[1;36m140\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'drop'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'building_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'building_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'drop'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2925\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2927\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2928\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2657\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'DT_D'"
     ]
    }
   ],
   "source": [
    "####### Remove 0 meter readings for site_id==0 #########\n",
    "\n",
    "\n",
    "df = building_df[building_df['site_id']==0]\n",
    "\n",
    "train_df['drop'] = np.where(train_df['DT_D']<=140, 1, 0)\n",
    "train_df['drop'] = np.where(train_df['building_id'].isin(df['building_id']), train_df['drop'], 0)\n",
    "\n",
    "train_df = train_df[train_df['drop']==0].reset_index(drop=True)\n",
    "\n",
    "del df, train_df['drop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Building DF merge through concat ###########\n",
    "\n",
    "\n",
    "# Benefits of concat:\n",
    "## Faster for huge datasets (columns number)\n",
    "## No dtype change for dataset\n",
    "## Consume less memmory \n",
    "\n",
    "temp_df = train_df[['building_id']]\n",
    "temp_df = temp_df.merge(building_df, on=['building_id'], how='left')\n",
    "del temp_df['building_id']\n",
    "train_df = pd.concat([train_df, temp_df], axis=1)\n",
    "\n",
    "temp_df = test_df[['building_id']]\n",
    "temp_df = temp_df.merge(building_df, on=['building_id'], how='left')\n",
    "del temp_df['building_id']\n",
    "test_df = pd.concat([test_df, temp_df], axis=1)\n",
    "\n",
    "del building_df, temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Weather DF merge over concat (to not lose type) #########\n",
    "\n",
    "# Benefits of concat:\n",
    "## Faster for huge datasets (columns number)\n",
    "## No dtype change for dataset\n",
    "## Consume less memmory \n",
    "\n",
    "temp_df = train_df[['site_id','timestamp']]\n",
    "temp_df = temp_df.merge(train_weather_df, on=['site_id','timestamp'], how='left')\n",
    "del temp_df['site_id'], temp_df['timestamp']\n",
    "train_df = pd.concat([train_df, temp_df], axis=1)\n",
    "\n",
    "temp_df = test_df[['site_id','timestamp']]\n",
    "temp_df = temp_df.merge(test_weather_df, on=['site_id','timestamp'], how='left')\n",
    "del temp_df['site_id'], temp_df['timestamp']\n",
    "test_df = pd.concat([test_df, temp_df], axis=1)\n",
    "\n",
    "del train_weather_df, test_weather_df, temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Delete some columns #######\n",
    "\n",
    "del test_df['row_id']\n",
    "\n",
    "i_cols = [\n",
    "         'timestamp',\n",
    "         'DT_D',\n",
    "         'DT_day_month',\n",
    "         'DT_week_month',\n",
    "        ]\n",
    "\n",
    "for col in i_cols:\n",
    "    try:\n",
    "        del train_df[col], test_df[col]\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Smooth readings ##########\n",
    "\n",
    "\n",
    "train_df['s_uid'] = train_df['site_id'].astype(str) +'_'+\\\n",
    "                    train_df['DT_M'].astype(str) +'_'+\\\n",
    "                    train_df['meter'].astype(str) +'_'+\\\n",
    "                    train_df['primary_use'].astype(str)\n",
    "\n",
    "temp_df = train_df.groupby(['s_uid'])[TARGET].apply(lambda x: int(np.percentile(x,99)))\n",
    "temp_df = temp_df.to_dict()\n",
    "\n",
    "train_df['s_uid'] = train_df['s_uid'].map(temp_df)\n",
    "train_df[TARGET] = np.where(train_df[TARGET]>train_df['s_uid'], train_df['s_uid'], train_df[TARGET])\n",
    "\n",
    "del train_df['s_uid'], temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Encode Meter ########\n",
    "\n",
    "# Building and site id\n",
    "for enc_col in ['building_id', 'site_id']:\n",
    "    temp_df = train_df.groupby([enc_col])['meter'].agg(['unique'])\n",
    "    temp_df['unique'] = temp_df['unique'].apply(lambda x: '_'.join(str(x))).astype(str)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    temp_df['unique'] = le.fit_transform(temp_df['unique']).astype(np.int8)\n",
    "    temp_df = temp_df['unique'].to_dict()\n",
    "\n",
    "    train_df[enc_col+'_uid_enc'] = train_df[enc_col].map(temp_df)\n",
    "    test_df[enc_col+'_uid_enc'] = test_df[enc_col].map(temp_df)\n",
    "    \n",
    "    # Nunique\n",
    "    temp_dict = train_df.groupby([enc_col])['meter'].agg(['nunique'])['nunique'].to_dict()\n",
    "    train_df[enc_col+'-m_nunique'] = train_df[enc_col].map(temp_dict).astype(np.int8)\n",
    "    test_df[enc_col+'-m_nunique'] = test_df[enc_col].map(temp_dict).astype(np.int8)\n",
    "\n",
    "del temp_df, temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Daily temperature ##########\n",
    "\n",
    "\n",
    "for df in [train_df, test_df]:\n",
    "    df['DT_w_hour'] = np.where((df['DT_hour']>5)&(df['DT_hour']<13),1,0)\n",
    "    df['DT_w_hour'] = np.where((df['DT_hour']>12)&(df['DT_hour']<19),2,df['DT_w_hour'])\n",
    "    df['DT_w_hour'] = np.where((df['DT_hour']>18),3,df['DT_w_hour'])\n",
    "\n",
    "    df['DT_w_temp'] = df.groupby(['site_id','DT_W','DT_w_hour'])['air_temperature'].transform('mean')\n",
    "    df['DT_w_dew_temp'] = df.groupby(['site_id','DT_W','DT_w_hour'])['dew_temperature'].transform('mean')\n",
    "\n",
    "i_cols = [\n",
    "         'DT_w_hour',\n",
    "        ]\n",
    "\n",
    "for col in i_cols:\n",
    "    del train_df[col], test_df[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 869.76 Mb (52.1% reduction)\n",
      "Mem. usage decreased to 1511.11 Mb (56.8% reduction)\n"
     ]
    }
   ],
   "source": [
    "####### Reduce memory usage ##############\n",
    "\n",
    "train_df = reduce_mem_usage(train_df)\n",
    "test_df = reduce_mem_usage(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Features ############\n",
    "\n",
    "\n",
    "remove_columns = [TARGET]\n",
    "features_columns = [col for col in list(train_df) if col not in remove_columns]\n",
    "\n",
    "categorical_features = [\n",
    "        'building_id',\n",
    "        'site_id',\n",
    "        'primary_use',\n",
    "        'DT_M',\n",
    "        'floor_count',\n",
    "        'building_id_uid_enc', \n",
    "        'site_id_uid_enc',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############ Store test_df to HDD and cleanup ###############\n",
    "\n",
    "test_df[features_columns].to_pickle('test_df.pkl')\n",
    "\n",
    "df = 0\n",
    "temp_df = 0\n",
    "temp_dict = 0\n",
    "i_cols = 0\n",
    "col = 0\n",
    "\n",
    "del test_df\n",
    "del df, temp_df, temp_dict\n",
    "del col, i_cols\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      train_df: 869.8MiB\n",
      "                           _i2:   2.4KiB\n",
      "                  LabelEncoder:   1.0KiB\n",
      "                          _i10:   878.0B\n",
      "                           _i1:   862.0B\n",
      "                           _i7:   726.0B\n",
      "                          _i11:   659.0B\n",
      "                           _i6:   619.0B\n",
      "                           _i9:   616.0B\n",
      "                           _i4:   492.0B\n",
      "Memory in Gb 1.18\n"
     ]
    }
   ],
   "source": [
    "########### Check memory usage ##############\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name,value in locals().items()),\n",
    "                         key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name,sizeof_fmt(size)))\n",
    "print('Memory in Gb', get_memory_usage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.9924012\ttotal: 2.28s\tremaining: 1h 16m 6s\n",
      "10:\tlearn: 1.4905643\ttotal: 24.7s\tremaining: 1h 14m 29s\n",
      "20:\tlearn: 1.3229203\ttotal: 45.3s\tremaining: 1h 11m 7s\n",
      "30:\tlearn: 1.2399368\ttotal: 1m 7s\tremaining: 1h 11m 10s\n",
      "40:\tlearn: 1.1788124\ttotal: 1m 28s\tremaining: 1h 10m 46s\n",
      "50:\tlearn: 1.1282261\ttotal: 1m 49s\tremaining: 1h 9m 48s\n",
      "60:\tlearn: 1.0923341\ttotal: 2m 10s\tremaining: 1h 9m 6s\n",
      "70:\tlearn: 1.0670265\ttotal: 2m 31s\tremaining: 1h 8m 26s\n",
      "80:\tlearn: 1.0464252\ttotal: 2m 54s\tremaining: 1h 8m 43s\n",
      "90:\tlearn: 1.0317135\ttotal: 3m 14s\tremaining: 1h 8m 3s\n",
      "100:\tlearn: 1.0212835\ttotal: 3m 34s\tremaining: 1h 7m 5s\n",
      "110:\tlearn: 1.0079763\ttotal: 3m 53s\tremaining: 1h 6m 16s\n",
      "120:\tlearn: 0.9984622\ttotal: 4m 11s\tremaining: 1h 5m 9s\n",
      "130:\tlearn: 0.9908158\ttotal: 4m 32s\tremaining: 1h 4m 47s\n",
      "140:\tlearn: 0.9818613\ttotal: 4m 50s\tremaining: 1h 3m 47s\n",
      "150:\tlearn: 0.9735852\ttotal: 5m 9s\tremaining: 1h 3m 13s\n",
      "160:\tlearn: 0.9669094\ttotal: 5m 27s\tremaining: 1h 2m 25s\n",
      "170:\tlearn: 0.9597137\ttotal: 5m 49s\tremaining: 1h 2m 21s\n",
      "180:\tlearn: 0.9541453\ttotal: 6m 10s\tremaining: 1h 2m 7s\n",
      "190:\tlearn: 0.9486204\ttotal: 6m 30s\tremaining: 1h 1m 34s\n",
      "200:\tlearn: 0.9431682\ttotal: 6m 49s\tremaining: 1h 1m 3s\n",
      "210:\tlearn: 0.9379464\ttotal: 7m 9s\tremaining: 1h 43s\n",
      "220:\tlearn: 0.9328416\ttotal: 7m 28s\tremaining: 1h 13s\n",
      "230:\tlearn: 0.9278346\ttotal: 7m 47s\tremaining: 59m 42s\n",
      "240:\tlearn: 0.9222238\ttotal: 8m 6s\tremaining: 59m 11s\n",
      "250:\tlearn: 0.9185132\ttotal: 8m 25s\tremaining: 58m 42s\n",
      "260:\tlearn: 0.9141849\ttotal: 8m 44s\tremaining: 58m 14s\n",
      "270:\tlearn: 0.9094542\ttotal: 9m 4s\tremaining: 57m 52s\n",
      "280:\tlearn: 0.9048427\ttotal: 9m 24s\tremaining: 57m 30s\n",
      "290:\tlearn: 0.9002665\ttotal: 9m 43s\tremaining: 57m 6s\n",
      "300:\tlearn: 0.8960704\ttotal: 10m 3s\tremaining: 56m 47s\n",
      "310:\tlearn: 0.8927780\ttotal: 10m 25s\tremaining: 56m 35s\n",
      "320:\tlearn: 0.8895301\ttotal: 10m 44s\tremaining: 56m 11s\n",
      "330:\tlearn: 0.8866903\ttotal: 11m 4s\tremaining: 55m 52s\n",
      "340:\tlearn: 0.8835385\ttotal: 11m 26s\tremaining: 55m 37s\n",
      "350:\tlearn: 0.8803089\ttotal: 11m 44s\tremaining: 55m 8s\n",
      "360:\tlearn: 0.8766247\ttotal: 12m 3s\tremaining: 54m 43s\n",
      "370:\tlearn: 0.8740397\ttotal: 12m 22s\tremaining: 54m 22s\n",
      "380:\tlearn: 0.8716865\ttotal: 12m 42s\tremaining: 53m 58s\n",
      "390:\tlearn: 0.8691308\ttotal: 13m\tremaining: 53m 30s\n",
      "400:\tlearn: 0.8666142\ttotal: 13m 19s\tremaining: 53m 7s\n",
      "410:\tlearn: 0.8637280\ttotal: 13m 41s\tremaining: 52m 54s\n",
      "420:\tlearn: 0.8614280\ttotal: 14m\tremaining: 52m 31s\n",
      "430:\tlearn: 0.8591419\ttotal: 14m 19s\tremaining: 52m 8s\n",
      "440:\tlearn: 0.8573010\ttotal: 14m 37s\tremaining: 51m 43s\n",
      "450:\tlearn: 0.8547146\ttotal: 14m 59s\tremaining: 51m 29s\n",
      "460:\tlearn: 0.8530064\ttotal: 15m 18s\tremaining: 51m 7s\n",
      "470:\tlearn: 0.8510331\ttotal: 15m 38s\tremaining: 50m 48s\n",
      "480:\tlearn: 0.8494364\ttotal: 15m 59s\tremaining: 50m 28s\n",
      "490:\tlearn: 0.8478957\ttotal: 16m 18s\tremaining: 50m 6s\n",
      "500:\tlearn: 0.8458106\ttotal: 16m 35s\tremaining: 49m 39s\n",
      "510:\tlearn: 0.8435465\ttotal: 16m 56s\tremaining: 49m 21s\n",
      "520:\tlearn: 0.8414395\ttotal: 17m 17s\tremaining: 49m 5s\n",
      "530:\tlearn: 0.8393845\ttotal: 17m 37s\tremaining: 48m 45s\n",
      "540:\tlearn: 0.8376237\ttotal: 17m 57s\tremaining: 48m 26s\n",
      "550:\tlearn: 0.8357870\ttotal: 18m 18s\tremaining: 48m 9s\n",
      "560:\tlearn: 0.8340288\ttotal: 18m 38s\tremaining: 47m 48s\n",
      "570:\tlearn: 0.8324443\ttotal: 18m 58s\tremaining: 47m 29s\n",
      "580:\tlearn: 0.8307273\ttotal: 19m 17s\tremaining: 47m 7s\n",
      "590:\tlearn: 0.8286912\ttotal: 19m 39s\tremaining: 46m 52s\n",
      "600:\tlearn: 0.8267956\ttotal: 19m 59s\tremaining: 46m 31s\n",
      "610:\tlearn: 0.8255478\ttotal: 20m 17s\tremaining: 46m 8s\n",
      "620:\tlearn: 0.8239482\ttotal: 20m 35s\tremaining: 45m 44s\n",
      "630:\tlearn: 0.8220763\ttotal: 20m 56s\tremaining: 45m 25s\n",
      "640:\tlearn: 0.8203758\ttotal: 21m 15s\tremaining: 45m 4s\n",
      "650:\tlearn: 0.8187242\ttotal: 21m 36s\tremaining: 44m 47s\n",
      "660:\tlearn: 0.8174697\ttotal: 21m 55s\tremaining: 44m 24s\n",
      "670:\tlearn: 0.8161281\ttotal: 22m 14s\tremaining: 44m 3s\n",
      "680:\tlearn: 0.8148560\ttotal: 22m 34s\tremaining: 43m 43s\n",
      "690:\tlearn: 0.8136630\ttotal: 22m 54s\tremaining: 43m 23s\n",
      "700:\tlearn: 0.8120522\ttotal: 23m 14s\tremaining: 43m 4s\n",
      "710:\tlearn: 0.8108138\ttotal: 23m 34s\tremaining: 42m 44s\n",
      "720:\tlearn: 0.8094423\ttotal: 23m 54s\tremaining: 42m 24s\n",
      "730:\tlearn: 0.8080857\ttotal: 24m 13s\tremaining: 42m 3s\n",
      "740:\tlearn: 0.8067039\ttotal: 24m 33s\tremaining: 41m 42s\n",
      "750:\tlearn: 0.8054933\ttotal: 24m 52s\tremaining: 41m 22s\n",
      "760:\tlearn: 0.8042708\ttotal: 25m 15s\tremaining: 41m 7s\n",
      "770:\tlearn: 0.8028661\ttotal: 25m 36s\tremaining: 40m 48s\n",
      "780:\tlearn: 0.8016645\ttotal: 25m 56s\tremaining: 40m 29s\n",
      "790:\tlearn: 0.8002865\ttotal: 26m 15s\tremaining: 40m 8s\n",
      "800:\tlearn: 0.7990990\ttotal: 26m 34s\tremaining: 39m 47s\n",
      "810:\tlearn: 0.7980055\ttotal: 26m 55s\tremaining: 39m 28s\n",
      "820:\tlearn: 0.7967278\ttotal: 27m 15s\tremaining: 39m 8s\n",
      "830:\tlearn: 0.7954510\ttotal: 27m 35s\tremaining: 38m 49s\n",
      "840:\tlearn: 0.7944642\ttotal: 27m 56s\tremaining: 38m 30s\n",
      "850:\tlearn: 0.7932279\ttotal: 28m 16s\tremaining: 38m 10s\n",
      "860:\tlearn: 0.7922010\ttotal: 28m 38s\tremaining: 37m 53s\n",
      "870:\tlearn: 0.7911835\ttotal: 28m 59s\tremaining: 37m 35s\n",
      "880:\tlearn: 0.7901825\ttotal: 29m 21s\tremaining: 37m 16s\n",
      "890:\tlearn: 0.7894042\ttotal: 29m 39s\tremaining: 36m 54s\n",
      "900:\tlearn: 0.7881862\ttotal: 29m 59s\tremaining: 36m 34s\n",
      "910:\tlearn: 0.7870199\ttotal: 30m 20s\tremaining: 36m 16s\n",
      "920:\tlearn: 0.7861687\ttotal: 30m 39s\tremaining: 35m 55s\n",
      "930:\tlearn: 0.7851369\ttotal: 30m 59s\tremaining: 35m 34s\n",
      "940:\tlearn: 0.7842142\ttotal: 31m 19s\tremaining: 35m 15s\n",
      "950:\tlearn: 0.7830369\ttotal: 31m 41s\tremaining: 34m 57s\n",
      "960:\tlearn: 0.7820584\ttotal: 32m 2s\tremaining: 34m 38s\n",
      "970:\tlearn: 0.7811649\ttotal: 32m 21s\tremaining: 34m 17s\n",
      "980:\tlearn: 0.7803983\ttotal: 32m 40s\tremaining: 33m 56s\n",
      "990:\tlearn: 0.7794465\ttotal: 33m 2s\tremaining: 33m 38s\n",
      "1000:\tlearn: 0.7785870\ttotal: 33m 22s\tremaining: 33m 18s\n",
      "1010:\tlearn: 0.7777171\ttotal: 33m 41s\tremaining: 32m 57s\n",
      "1020:\tlearn: 0.7766515\ttotal: 34m 3s\tremaining: 32m 39s\n",
      "1030:\tlearn: 0.7757650\ttotal: 34m 23s\tremaining: 32m 19s\n",
      "1040:\tlearn: 0.7748957\ttotal: 34m 44s\tremaining: 31m 59s\n",
      "1050:\tlearn: 0.7739829\ttotal: 35m 2s\tremaining: 31m 38s\n",
      "1060:\tlearn: 0.7731470\ttotal: 35m 23s\tremaining: 31m 19s\n",
      "1070:\tlearn: 0.7723686\ttotal: 35m 42s\tremaining: 30m 58s\n",
      "1080:\tlearn: 0.7715025\ttotal: 36m 1s\tremaining: 30m 37s\n",
      "1090:\tlearn: 0.7706285\ttotal: 36m 23s\tremaining: 30m 19s\n",
      "1100:\tlearn: 0.7697686\ttotal: 36m 44s\tremaining: 29m 59s\n",
      "1110:\tlearn: 0.7689309\ttotal: 37m 7s\tremaining: 29m 42s\n",
      "1120:\tlearn: 0.7680844\ttotal: 37m 29s\tremaining: 29m 23s\n",
      "1130:\tlearn: 0.7672597\ttotal: 37m 48s\tremaining: 29m 2s\n",
      "1140:\tlearn: 0.7663813\ttotal: 38m 9s\tremaining: 28m 43s\n",
      "1150:\tlearn: 0.7657126\ttotal: 38m 28s\tremaining: 28m 23s\n",
      "1160:\tlearn: 0.7649494\ttotal: 38m 49s\tremaining: 28m 3s\n",
      "1170:\tlearn: 0.7642600\ttotal: 39m 10s\tremaining: 27m 43s\n",
      "1180:\tlearn: 0.7634422\ttotal: 39m 30s\tremaining: 27m 24s\n",
      "1190:\tlearn: 0.7624613\ttotal: 39m 52s\tremaining: 27m 5s\n",
      "1200:\tlearn: 0.7617622\ttotal: 40m 10s\tremaining: 26m 43s\n",
      "1210:\tlearn: 0.7611982\ttotal: 40m 31s\tremaining: 26m 23s\n",
      "1220:\tlearn: 0.7605600\ttotal: 40m 51s\tremaining: 26m 4s\n",
      "1230:\tlearn: 0.7596921\ttotal: 41m 13s\tremaining: 25m 45s\n",
      "1240:\tlearn: 0.7590566\ttotal: 41m 32s\tremaining: 25m 24s\n",
      "1250:\tlearn: 0.7584110\ttotal: 41m 51s\tremaining: 25m 3s\n",
      "1260:\tlearn: 0.7577807\ttotal: 42m 9s\tremaining: 24m 42s\n",
      "1270:\tlearn: 0.7572468\ttotal: 42m 28s\tremaining: 24m 21s\n",
      "1280:\tlearn: 0.7565572\ttotal: 42m 47s\tremaining: 24m 1s\n",
      "1290:\tlearn: 0.7558616\ttotal: 43m 9s\tremaining: 23m 42s\n",
      "1300:\tlearn: 0.7550950\ttotal: 43m 30s\tremaining: 23m 22s\n",
      "1310:\tlearn: 0.7541545\ttotal: 43m 52s\tremaining: 23m 3s\n",
      "1320:\tlearn: 0.7535026\ttotal: 44m 13s\tremaining: 22m 43s\n",
      "1330:\tlearn: 0.7526134\ttotal: 44m 33s\tremaining: 22m 23s\n",
      "1340:\tlearn: 0.7517634\ttotal: 44m 54s\tremaining: 22m 4s\n",
      "1350:\tlearn: 0.7511842\ttotal: 45m 14s\tremaining: 21m 44s\n",
      "1360:\tlearn: 0.7506472\ttotal: 45m 33s\tremaining: 21m 23s\n",
      "1370:\tlearn: 0.7500633\ttotal: 45m 53s\tremaining: 21m 3s\n",
      "1380:\tlearn: 0.7493542\ttotal: 46m 17s\tremaining: 20m 44s\n",
      "1390:\tlearn: 0.7486735\ttotal: 46m 37s\tremaining: 20m 24s\n",
      "1400:\tlearn: 0.7480559\ttotal: 46m 58s\tremaining: 20m 4s\n",
      "1410:\tlearn: 0.7473850\ttotal: 47m 18s\tremaining: 19m 44s\n",
      "1420:\tlearn: 0.7466849\ttotal: 47m 39s\tremaining: 19m 25s\n",
      "1430:\tlearn: 0.7461107\ttotal: 48m 1s\tremaining: 19m 5s\n",
      "1440:\tlearn: 0.7455459\ttotal: 48m 20s\tremaining: 18m 45s\n",
      "1450:\tlearn: 0.7449808\ttotal: 48m 39s\tremaining: 18m 24s\n",
      "1460:\tlearn: 0.7443340\ttotal: 49m\tremaining: 18m 4s\n",
      "1470:\tlearn: 0.7437173\ttotal: 49m 19s\tremaining: 17m 44s\n",
      "1480:\tlearn: 0.7431043\ttotal: 49m 39s\tremaining: 17m 24s\n",
      "1490:\tlearn: 0.7425387\ttotal: 50m\tremaining: 17m 4s\n",
      "1500:\tlearn: 0.7419835\ttotal: 50m 22s\tremaining: 16m 44s\n",
      "1510:\tlearn: 0.7414291\ttotal: 50m 40s\tremaining: 16m 23s\n",
      "1520:\tlearn: 0.7409245\ttotal: 51m\tremaining: 16m 3s\n",
      "1530:\tlearn: 0.7403661\ttotal: 51m 19s\tremaining: 15m 43s\n",
      "1540:\tlearn: 0.7396259\ttotal: 51m 37s\tremaining: 15m 22s\n",
      "1550:\tlearn: 0.7391114\ttotal: 51m 57s\tremaining: 15m 2s\n",
      "1560:\tlearn: 0.7383544\ttotal: 52m 17s\tremaining: 14m 42s\n",
      "1570:\tlearn: 0.7379334\ttotal: 52m 36s\tremaining: 14m 21s\n",
      "1580:\tlearn: 0.7373434\ttotal: 52m 58s\tremaining: 14m 2s\n",
      "1590:\tlearn: 0.7367430\ttotal: 53m 19s\tremaining: 13m 42s\n",
      "1600:\tlearn: 0.7362336\ttotal: 53m 39s\tremaining: 13m 22s\n",
      "1610:\tlearn: 0.7356409\ttotal: 53m 59s\tremaining: 13m 2s\n",
      "1620:\tlearn: 0.7350530\ttotal: 54m 17s\tremaining: 12m 41s\n",
      "1630:\tlearn: 0.7345239\ttotal: 54m 38s\tremaining: 12m 21s\n",
      "1640:\tlearn: 0.7339150\ttotal: 54m 58s\tremaining: 12m 1s\n",
      "1650:\tlearn: 0.7334598\ttotal: 55m 19s\tremaining: 11m 41s\n",
      "1660:\tlearn: 0.7328966\ttotal: 55m 41s\tremaining: 11m 21s\n",
      "1670:\tlearn: 0.7324757\ttotal: 56m 2s\tremaining: 11m 1s\n",
      "1680:\tlearn: 0.7318733\ttotal: 56m 22s\tremaining: 10m 41s\n",
      "1690:\tlearn: 0.7313374\ttotal: 56m 43s\tremaining: 10m 21s\n",
      "1700:\tlearn: 0.7308971\ttotal: 57m 2s\tremaining: 10m 1s\n",
      "1710:\tlearn: 0.7304708\ttotal: 57m 21s\tremaining: 9m 41s\n",
      "1720:\tlearn: 0.7298844\ttotal: 57m 40s\tremaining: 9m 21s\n",
      "1730:\tlearn: 0.7294463\ttotal: 58m\tremaining: 9m\n",
      "1740:\tlearn: 0.7289823\ttotal: 58m 20s\tremaining: 8m 40s\n",
      "1750:\tlearn: 0.7284920\ttotal: 58m 39s\tremaining: 8m 20s\n",
      "1760:\tlearn: 0.7280491\ttotal: 58m 58s\tremaining: 8m\n",
      "1770:\tlearn: 0.7276042\ttotal: 59m 18s\tremaining: 7m 40s\n",
      "1780:\tlearn: 0.7272500\ttotal: 59m 37s\tremaining: 7m 19s\n",
      "1790:\tlearn: 0.7266605\ttotal: 59m 58s\tremaining: 6m 59s\n",
      "1800:\tlearn: 0.7261923\ttotal: 1h 19s\tremaining: 6m 39s\n",
      "1810:\tlearn: 0.7257076\ttotal: 1h 40s\tremaining: 6m 19s\n",
      "1820:\tlearn: 0.7252376\ttotal: 1h 1m\tremaining: 5m 59s\n",
      "1830:\tlearn: 0.7248446\ttotal: 1h 1m 19s\tremaining: 5m 39s\n",
      "1840:\tlearn: 0.7244091\ttotal: 1h 1m 38s\tremaining: 5m 19s\n",
      "1850:\tlearn: 0.7239032\ttotal: 1h 1m 59s\tremaining: 4m 59s\n",
      "1860:\tlearn: 0.7234663\ttotal: 1h 2m 18s\tremaining: 4m 39s\n",
      "1870:\tlearn: 0.7230048\ttotal: 1h 2m 36s\tremaining: 4m 19s\n",
      "1880:\tlearn: 0.7225143\ttotal: 1h 2m 56s\tremaining: 3m 58s\n",
      "1890:\tlearn: 0.7220779\ttotal: 1h 3m 16s\tremaining: 3m 38s\n",
      "1900:\tlearn: 0.7216400\ttotal: 1h 3m 35s\tremaining: 3m 18s\n",
      "1910:\tlearn: 0.7211934\ttotal: 1h 3m 56s\tremaining: 2m 58s\n",
      "1920:\tlearn: 0.7207888\ttotal: 1h 4m 15s\tremaining: 2m 38s\n",
      "1930:\tlearn: 0.7203913\ttotal: 1h 4m 35s\tremaining: 2m 18s\n",
      "1940:\tlearn: 0.7199983\ttotal: 1h 4m 54s\tremaining: 1m 58s\n",
      "1950:\tlearn: 0.7194702\ttotal: 1h 5m 15s\tremaining: 1m 38s\n",
      "1960:\tlearn: 0.7190039\ttotal: 1h 5m 35s\tremaining: 1m 18s\n",
      "1970:\tlearn: 0.7184955\ttotal: 1h 5m 57s\tremaining: 58.2s\n",
      "1980:\tlearn: 0.7181391\ttotal: 1h 6m 16s\tremaining: 38.1s\n",
      "1990:\tlearn: 0.7176752\ttotal: 1h 6m 35s\tremaining: 18.1s\n",
      "1999:\tlearn: 0.7172486\ttotal: 1h 6m 53s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########### Catboost Model ################\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "model_filename = 'catboost'\n",
    "models = []\n",
    "\n",
    "cat_params = {\n",
    "        'n_estimators': 2000,\n",
    "        'learning_rate': 0.1,\n",
    "        'eval_metric': 'RMSE',\n",
    "        'loss_function': 'RMSE',\n",
    "        'random_seed': SEED,\n",
    "        'metric_period': 10,\n",
    "        'task_type': 'GPU',\n",
    "        'depth': 8,\n",
    "    }\n",
    "\n",
    "estimator = CatBoostRegressor(**cat_params)\n",
    "estimator.fit(\n",
    "            train_df[features_columns], np.log1p(train_df[TARGET]),\n",
    "            cat_features=categorical_features,\n",
    "            verbose=True)\n",
    "\n",
    "estimator.save_model(model_filename + '.bin')\n",
    "models.append(model_filename + '.bin')\n",
    "\n",
    "del estimator\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for catboost.bin\n",
      "Predicting batch: 0\n",
      "Predicting batch: 1\n",
      "Predicting batch: 2\n",
      "Predicting batch: 3\n",
      "Predicting batch: 4\n",
      "Predicting batch: 5\n",
      "Predicting batch: 6\n",
      "Predicting batch: 7\n",
      "Predicting batch: 8\n",
      "Predicting batch: 9\n",
      "Predicting batch: 10\n",
      "Predicting batch: 11\n",
      "Predicting batch: 12\n",
      "Predicting batch: 13\n",
      "Predicting batch: 14\n",
      "Predicting batch: 15\n",
      "Predicting batch: 16\n",
      "Predicting batch: 17\n",
      "Predicting batch: 18\n",
      "Predicting batch: 19\n",
      "Predicting batch: 20\n",
      "Predicting batch: 21\n",
      "Predicting batch: 22\n",
      "Predicting batch: 23\n",
      "Predicting batch: 24\n",
      "Predicting batch: 25\n",
      "Predicting batch: 26\n",
      "Predicting batch: 27\n",
      "Predicting batch: 28\n",
      "Predicting batch: 29\n",
      "Predicting batch: 30\n",
      "Predicting batch: 31\n",
      "Predicting batch: 32\n",
      "Predicting batch: 33\n",
      "Predicting batch: 34\n",
      "Predicting batch: 35\n",
      "Predicting batch: 36\n",
      "Predicting batch: 37\n",
      "Predicting batch: 38\n",
      "Predicting batch: 39\n",
      "Predicting batch: 40\n",
      "Predicting batch: 41\n",
      "Predicting batch: 42\n",
      "Predicting batch: 43\n",
      "Predicting batch: 44\n",
      "Predicting batch: 45\n",
      "Predicting batch: 46\n",
      "Predicting batch: 47\n",
      "Predicting batch: 48\n",
      "Predicting batch: 49\n",
      "Predicting batch: 50\n",
      "Predicting batch: 51\n",
      "Predicting batch: 52\n",
      "Predicting batch: 53\n",
      "Predicting batch: 54\n",
      "Predicting batch: 55\n",
      "Predicting batch: 56\n",
      "Predicting batch: 57\n",
      "Predicting batch: 58\n",
      "Predicting batch: 59\n",
      "Predicting batch: 60\n",
      "Predicting batch: 61\n",
      "Predicting batch: 62\n",
      "Predicting batch: 63\n",
      "Predicting batch: 64\n",
      "Predicting batch: 65\n",
      "Predicting batch: 66\n",
      "Predicting batch: 67\n",
      "Predicting batch: 68\n",
      "Predicting batch: 69\n",
      "Predicting batch: 70\n",
      "Predicting batch: 71\n",
      "Predicting batch: 72\n",
      "Predicting batch: 73\n",
      "Predicting batch: 74\n",
      "Predicting batch: 75\n",
      "Predicting batch: 76\n",
      "Predicting batch: 77\n",
      "Predicting batch: 78\n",
      "Predicting batch: 79\n",
      "Predicting batch: 80\n",
      "Predicting batch: 81\n",
      "Predicting batch: 82\n",
      "Predicting batch: 83\n",
      "    meter_reading  row_id\n",
      "0      185.433733       0\n",
      "1      133.584043       1\n",
      "2        8.246674       2\n",
      "3      276.786557       3\n",
      "4      889.044917       4\n",
      "5        9.560042       5\n",
      "6      138.184662       6\n",
      "7      328.594530       7\n",
      "8       87.551798       8\n",
      "9      415.468948       9\n",
      "10     141.143793      10\n",
      "11      20.388539      11\n",
      "12    1346.170611      12\n",
      "13     300.513289      13\n",
      "14     209.018462      14\n",
      "15     248.640299      15\n",
      "16      35.004570      16\n",
      "17     222.128499      17\n",
      "18      88.939049      18\n",
      "19     112.908454      19\n",
      "count    4.169760e+07\n",
      "mean     6.331758e+02\n",
      "std      2.495431e+04\n",
      "min      0.000000e+00\n",
      "25%      1.853253e+01\n",
      "50%      7.462674e+01\n",
      "75%      2.458003e+02\n",
      "max      7.440143e+06\n",
      "Name: meter_reading, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "######### Predict ##############\n",
    "\n",
    "if not LOCAl_TEST:\n",
    "   \n",
    "    # delete train_df\n",
    "    del train_df\n",
    "\n",
    "    # Read test file\n",
    "    test_df = pd.read_pickle('test_df.pkl')\n",
    "    \n",
    "    # Remove test_df from hdd\n",
    "    os.system('rm test_df.pkl')\n",
    " \n",
    "    # Read submission file\n",
    "    submission = pd.read_csv('../input/ashrae-energy-prediction/sample_submission.csv')\n",
    "\n",
    "    # Remove row_id for a while\n",
    "    del submission['row_id']\n",
    "    \n",
    "    for model_path in models:\n",
    "        print('Predictions for', model_path)\n",
    "        \n",
    "        if 'catboost' in model_path:\n",
    "            estimator = CatBoostRegressor()\n",
    "            estimator.load_model(model_path)\n",
    "        else:\n",
    "            estimator = pickle.load(open(model_path, 'rb'))\n",
    "\n",
    "        predictions = []\n",
    "        batch_size = 500000\n",
    "        for batch in range(int(len(test_df)/batch_size)+1):\n",
    "            print('Predicting batch:', batch)\n",
    "            predictions += list(np.expm1(estimator.predict(test_df[features_columns].iloc[batch*batch_size:(batch+1)*batch_size])))\n",
    "            \n",
    "        submission['meter_reading'] += predictions\n",
    "        \n",
    "    # Average over models\n",
    "    submission['meter_reading'] /= len(models)\n",
    "    \n",
    "    # Delete test_df\n",
    "    del test_df\n",
    "     \n",
    "    # Fix negative values\n",
    "    submission['meter_reading'] = submission['meter_reading'].clip(0,None)\n",
    "\n",
    "    # Restore row_id\n",
    "    submission['row_id'] = submission.index\n",
    "    \n",
    "    \n",
    "    ########## Check ###########\n",
    "    print(submission.iloc[:20])\n",
    "    print(submission['meter_reading'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Export ###############\n",
    "\n",
    "if not LOCAl_TEST:\n",
    "    submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
