{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "import os, gc, sys, warnings, random, math, psutil, pickle\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Helpers ######\n",
    "\n",
    "\n",
    "## Seeder\n",
    "# :seed to make all processes deterministic     # type: int\n",
    "def seed_everything(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "## Simple \"Memory profilers\" to see memory usage\n",
    "def get_memory_usage():\n",
    "    return np.round(psutil.Process(os.getpid()).memory_info()[0]/2.**30, 2) \n",
    "        \n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f%s%s\" % (num, 'Yi', suffix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Vars ######\n",
    "\n",
    "SEED = 42\n",
    "LOCAl_TEST = False\n",
    "seed_everything(SEED)\n",
    "TARGET = 'meter_reading'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "test_df = pd.read_csv('test.csv') # Load test data\n",
    "\n",
    "building_df = pd.read_csv('building_metadata.csv')\n",
    "\n",
    "train_weather_df = pd.read_csv('weather_train.csv')\n",
    "\n",
    "test_weather_df = pd.read_csv('weather_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Building DF merge through concat ########################\n",
    "# Benefits of concat:\n",
    "## Faster for huge datasets (columns number)\n",
    "## No dtype change for dataset\n",
    "## Consume less memmory \n",
    "\n",
    "temp_df = train_df[['building_id']]\n",
    "temp_df = temp_df.merge(building_df, on=['building_id'], how='left')\n",
    "del temp_df['building_id']\n",
    "train_df = pd.concat([train_df, temp_df], axis=1)\n",
    "\n",
    "temp_df = test_df[['building_id']]\n",
    "temp_df = temp_df.merge(building_df, on=['building_id'], how='left')\n",
    "del temp_df['building_id']\n",
    "test_df = pd.concat([test_df, temp_df], axis=1)\n",
    "\n",
    "del building_df, temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Weather DF merge over concat (to not lose type) ###########################\n",
    "# Benefits of concat:\n",
    "## Faster for huge datasets (columns number)\n",
    "## No dtype change for dataset\n",
    "## Consume less memmory \n",
    "\n",
    "temp_df = train_df[['site_id','timestamp']]\n",
    "temp_df = temp_df.merge(train_weather_df, on=['site_id','timestamp'], how='left')\n",
    "del temp_df['site_id'], temp_df['timestamp']\n",
    "train_df = pd.concat([train_df, temp_df], axis=1)\n",
    "\n",
    "temp_df = test_df[['site_id','timestamp']]\n",
    "temp_df = temp_df.merge(test_weather_df, on=['site_id','timestamp'], how='left')\n",
    "del temp_df['site_id'], temp_df['timestamp']\n",
    "test_df = pd.concat([test_df, temp_df], axis=1)\n",
    "\n",
    "del train_weather_df, test_weather_df, temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############# Trick to use kernel hdd to store results #############\n",
    "\n",
    "# You can save just test_df or both if have sufficient space\n",
    "train_df.to_pickle('train_df.pkl')\n",
    "test_df.to_pickle('test_df.pkl')\n",
    "   \n",
    "del train_df, test_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           _i1:   815.0B\n",
      "                           _ii:   752.0B\n",
      "                           _i6:   752.0B\n",
      "                          _iii:   635.0B\n",
      "                           _i5:   635.0B\n",
      "                           _i2:   620.0B\n",
      "                           _i8:   374.0B\n",
      "                           _i4:   292.0B\n",
      "                            _i:   286.0B\n",
      "                           _i7:   286.0B\n",
      "Memory in Gb 0.06\n"
     ]
    }
   ],
   "source": [
    "########################### Check memory usage #################################\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name,value in locals().items()),\n",
    "                         key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name,sizeof_fmt(size)))\n",
    "print('Memory in Gb', get_memory_usage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model params\n",
    "\n",
    "import lightgbm as lgb\n",
    "lgb_params = {\n",
    "                    'objective':'regression',\n",
    "                    'boosting_type':'gbdt',\n",
    "                    'metric':'rmse',\n",
    "                    'n_jobs':-1,\n",
    "                    'learning_rate':0.05,\n",
    "                    'num_leaves': 2**8,\n",
    "                    'max_depth':-1,\n",
    "                    'tree_learner':'serial',\n",
    "                    'colsample_bytree': 0.7,\n",
    "                    'subsample_freq':1,\n",
    "                    'subsample':0.7,\n",
    "                    'n_estimators':800,\n",
    "                    'max_bin':255,\n",
    "                    'verbose':-1,\n",
    "                    'seed': SEED,\n",
    "                    'early_stopping_rounds':100, \n",
    "                } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LightGBM Method for create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float or bool.\nDid not expect the data types in the following fields: primary_use",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-dab46e1fba67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[0mtr_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[0mvalid_sets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval_sets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                 \u001b[0mverbose_eval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             )\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[1;31m# construct booster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         \u001b[0mbooster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[0;32m   1712\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1713\u001b[0m             _safe_call(_LIB.LGBM_BoosterCreate(\n\u001b[1;32m-> 1714\u001b[1;33m                 \u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1715\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1716\u001b[0m                 ctypes.byref(self.handle)))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1083\u001b[0m                                 \u001b[0minit_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m                                 \u001b[0msilent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msilent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1085\u001b[1;33m                                 categorical_feature=self.categorical_feature, params=self.params)\n\u001b[0m\u001b[0;32m   1086\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfree_raw_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1087\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[0;32m    828\u001b[0m                                                                                              \u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    829\u001b[0m                                                                                              \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 830\u001b[1;33m                                                                                              self.pandas_categorical)\n\u001b[0m\u001b[0;32m    831\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_label_from_pandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_data_from_pandas\u001b[1;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[0;32m    342\u001b[0m             raise ValueError(\"DataFrame.dtypes for data must be int, float or bool.\\n\"\n\u001b[0;32m    343\u001b[0m                              \u001b[1;34m\"Did not expect the data types in the following fields: \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m                              + ', '.join(data.columns[bad_indices]))\n\u001b[0m\u001b[0;32m    345\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float or bool.\nDid not expect the data types in the following fields: primary_use"
     ]
    }
   ],
   "source": [
    "# Models saving\n",
    "model_filename = 'lgbm'\n",
    "models = []\n",
    "\n",
    "# Load train_df from hdd\n",
    "train_df = pd.read_pickle('train_df.pkl')\n",
    "\n",
    "remove_columns = ['timestamp',TARGET]\n",
    "features_columns = [col for col in list(train_df) if col not in remove_columns]\n",
    "\n",
    "if LOCAl_TEST:\n",
    "    tr_data = lgb.Dataset(train_df.iloc[:15000000][features_columns], label=np.log1p(train_df.iloc[:15000000][TARGET]))\n",
    "    vl_data = lgb.Dataset(train_df.iloc[15000000:][features_columns], label=np.log1p(train_df.iloc[15000000:][TARGET]))\n",
    "    eval_sets = [tr_data,vl_data]\n",
    "else:\n",
    "    tr_data = lgb.Dataset(train_df[features_columns], label=np.log1p(train_df[TARGET]))\n",
    "    eval_sets = [tr_data]\n",
    "\n",
    "# Remove train_df from hdd\n",
    "os.system('rm train_df.pkl')\n",
    "\n",
    "# Lets make 5 seeds mix model\n",
    "for cur_seed in [42,43,44,45,46]:\n",
    "    \n",
    "    # Seed everything\n",
    "    seed_everything(cur_seed)\n",
    "    lgb_params['seed'] = cur_seed\n",
    "    \n",
    "    estimator = lgb.train(\n",
    "                lgb_params,\n",
    "                tr_data,\n",
    "                valid_sets = eval_sets,\n",
    "                verbose_eval = 100,\n",
    "            )\n",
    "\n",
    "    # For CV you may add fold number\n",
    "    # pickle.dump(estimator, open(model_filename + '__fold_' + str(i) + '.bin', \"wb\"))\n",
    "    pickle.dump(estimator, open(model_filename + '__seed_' + str(cur_seed)  + '.bin', 'wb'))\n",
    "    models.append(model_filename + '__seed_' + str(cur_seed)  + '.bin')\n",
    "\n",
    "if not LOCAl_TEST:\n",
    "    del tr_data, train_df\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Predict #############\n",
    "\n",
    "if not LOCAl_TEST:\n",
    "    \n",
    "    # Load test_df from hdd\n",
    "    test_df = pd.read_pickle('test_df.pkl')\n",
    "    \n",
    "    # Remove unused columns\n",
    "    test_df = test_df[features_columns]\n",
    "    \n",
    "    # Remove test_df from hdd\n",
    "    os.system('rm test_df.pkl')\n",
    "    \n",
    "    # Read submission file\n",
    "    submission = pd.read_csv('../input/ashrae-energy-prediction/sample_submission.csv')\n",
    "\n",
    "    # Remove row_id for a while\n",
    "    del submission['row_id']\n",
    "    \n",
    "    for model_path in models:\n",
    "        print('Predictions for', model_path)\n",
    "        estimator = pickle.load(open(model_path, 'rb'))\n",
    "\n",
    "        predictions = []\n",
    "        batch_size = 2000000\n",
    "        for batch in range(int(len(test_df)/batch_size)+1):\n",
    "            print('Predicting batch:', batch)\n",
    "            predictions += list(np.expm1(estimator.predict(test_df[features_columns].iloc[batch*batch_size:(batch+1)*batch_size])))\n",
    "            \n",
    "        submission['meter_reading'] += predictions\n",
    "        \n",
    "    # Average over models\n",
    "    submission['meter_reading'] /= len(models)\n",
    "    \n",
    "    # Delete test_df\n",
    "    del test_df\n",
    "     \n",
    "    # Fix negative values\n",
    "    submission['meter_reading'] = submission['meter_reading'].clip(0,None)\n",
    "\n",
    "    # Restore row_id\n",
    "    submission['row_id'] = submission.index\n",
    "    \n",
    "    \n",
    "    \n",
    "    #### Check ####\n",
    "    \n",
    "    print(submission.iloc[:20])\n",
    "    print(submission['meter_reading'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
